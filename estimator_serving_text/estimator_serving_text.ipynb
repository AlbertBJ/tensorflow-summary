{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 本文主要针对 使用estimator serving（详见[github](https://github.com/AlbertBJ/estimator)）时遇到的问题进行说明,：\n",
    "\n",
    "问题：<br>\n",
    "1. serving时，如何将 输入文本 转换为 id 列表，再feed NN\n",
    "2. predict返回时，如何将 id转换为 文本\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来 说一下 用到的 相关 API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.contrib.lookup.index_table_from_file\n",
    "\n",
    "tf.contrib.lookup.index_table_from_file(<br>\n",
    "    vocabulary_file=None,<br>\n",
    "    num_oov_buckets=0,<br>\n",
    "    vocab_size=None,<br>\n",
    "    default_value=-1,<br>\n",
    "    hasher_spec=tf.contrib.lookup.FastHashSpec,<br>\n",
    "    key_dtype=tf.dtypes.string,<br>\n",
    "    name=None,<br>\n",
    "    key_column_index=TextFileIndex.WHOLE_LINE,<br>\n",
    "    value_column_index=TextFileIndex.LINE_NUMBER,<br>\n",
    "    delimiter='\\t'<br>\n",
    ")<br>\n",
    "作用：通过 读取已经持久化的 字典文件，从而将 文本转换为 int64的id;该函数 返回的是 一个lookup table,利用 lookup table进行转换<br>\n",
    "参数：<br>\n",
    "    vocabulary_file=字典文件,<br>\n",
    "    num_oov_buckets,超出字典外的 词使用的 id值，范围是[vocab_size,vocab_size+num_oov_buckets-1]<br>\n",
    "    vocab_size,字典文件大小<br>\n",
    "    default_value,超出字典外的 词 使用的 id值<br>\n",
    "    hasher_spec 对超出 字典范围 的特征 进行 id赋值的 hash算法<br>\n",
    "    key_dtype 就是文件中 字或者词的类型<br>\n",
    "    name 此op的name<br>\n",
    "    key_column_index= 此值 和 下面的值 都是 为了 解决 key的问题，比如，是一行一个key还是 一行多个key<br>\n",
    "    value_column_index<br>\n",
    "    delimiter 一行中 分割 字段的 分隔符，针对 上面说的 一行多个key的 问题<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "strs=['emerson lake and palmer','emerson palmer test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"SparseToDense_1:0\", shape=(2, 4), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "# 若要使用 lookup table 则首先需要将 每一个 文本拆分为 向量，此例子中 将两个文本分别拆分为 两个向量 并形成 矩阵\n",
    "features=tf.constant(strs )\n",
    "words=tf.string_split(features)\n",
    "densewords=tf.sparse_tensor_to_dense(words,default_value='UNK') # 使用 UNK来标识 未知 word\n",
    "# features=tf.constant(['emerson lake and palmer']) \n",
    "\n",
    "print(densewords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "table=tf.contrib.lookup.index_table_from_file(vocabulary_file='data/vocab.txt',num_oov_buckets=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.ops.lookup_ops.IdTableWithHashBuckets at 0x22551018ba8>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.Tensor"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(densewords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'string_to_index_4_Lookup:0' shape=(2, 4) dtype=int64>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt=table.lookup(densewords) # 根据对应的key 在lookup table中获得对应的 id\n",
    "tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[b'emerson' b'lake' b'and' b'palmer']\n",
      " [b'emerson' b'palmer' b'test' b'UNK']]\n",
      "[[0 1 3 2]\n",
      " [0 2 3 3]]\n",
      "(2, 4)\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.tables_initializer())\n",
    "    ori=sess.run(densewords)\n",
    "    print(ori)\n",
    "    v=sess.run(tt)\n",
    "    print(v) # 获取 对应 的 id\n",
    "    print(v.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.contrib.lookup.index_table_from_tensor\n",
    "\n",
    "tf.contrib.lookup.index_table_from_tensor(<br>\n",
    "    mapping,<br>\n",
    "    num_oov_buckets=0,<br>\n",
    "    default_value=-1,<br>\n",
    "    hasher_spec=tf.contrib.lookup.FastHashSpec,<br>\n",
    "    dtype=tf.dtypes.string,<br>\n",
    "    name=None<br>\n",
    ")<br>\n",
    "作用：与index_table_from_file作用类似，区别在于 此方法 是根据 tensor形成 lookup table<br>\n",
    "参数：<br>\n",
    "其它参数 同上，下面主要说一下 mapping<br>\n",
    "    mapping: 1维tensor,可以理解为 他就是一个 向量，key和value分别是 tensor的 元素和元素的索引   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\Python\\virtualenv\\fc\\lib\\site-packages\\tensorflow\\python\\ops\\lookup_ops.py:1137: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.ops.lookup_ops.IdTableWithHashBuckets at 0x2254f2c5400>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_tensor=tf.contrib.lookup.index_table_from_tensor(mapping=tf.constant(['emerson', 'lake', 'and', 'palmer']),num_oov_buckets=1)\n",
    "table_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 2 3]\n",
      " [0 3 4 4]]\n"
     ]
    }
   ],
   "source": [
    "# 使用上面的densewords\n",
    "v=table_tensor.lookup(densewords)\n",
    "with tf.Session() as s:\n",
    "    s.run(tf.tables_initializer())\n",
    "    re=s.run(v)\n",
    "    print(re) # 可以参照 table自己 数一下 索引"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上可以理解为 word2id的过程，那么下面 就来说一下 id2word的过程\n",
    "\n",
    "# tf.contrib.lookup.index_to_string_table_from_file\n",
    "\n",
    "tf.contrib.lookup.index_to_string_table_from_file(<br>\n",
    "    vocabulary_file,<br>\n",
    "    vocab_size=None,<br>\n",
    "    default_value='UNK',<br>\n",
    "    name=None,<br>\n",
    "    key_column_index=TextFileIndex.LINE_NUMBER,<br>\n",
    "    value_column_index=TextFileIndex.WHOLE_LINE,<br>\n",
    "    delimiter='\\t'<br>\n",
    ")<br>\n",
    "作用： 生成 实现id2word过程 的lookup table<br>\n",
    "参数：同 .index_table_from_file<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.ops.lookup_ops.HashTable at 0x225508f6048>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_2id=tf.contrib.lookup.index_to_string_table_from_file(vocabulary_file='data/vocab.txt',default_value='UNK')\n",
    "table_2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[b'emerson' b'lake' b'palmer' b'UNK']\n",
      " [b'emerson' b'UNK' b'UNK' b'UNK']]\n"
     ]
    }
   ],
   "source": [
    "word2id=tf.constant([[0, 1, 2, 3] ,[0 ,3 ,4, 9]],dtype=tf.int64)\n",
    "wordlist=table_2id.lookup(word2id)\n",
    "with tf.Session() as ss:\n",
    "    ss.run(tf.tables_initializer())\n",
    "    print(ss.run(wordlist)) # 我的vocab中 只有 emerson lake palmer三个词，对应索引 分别为 0,1,2 ，所以 结果中 会有 很多 UNK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.contrib.lookup.index_to_string_table_from_tensor\n",
    "\n",
    "tf.contrib.lookup.index_to_string_table_from_tensor(<br>\n",
    "    mapping,<br>\n",
    "    default_value='UNK',<br>\n",
    "    name=None<br>\n",
    ")<br>\n",
    "作用：作用同 index_to_string_table_from_file，可以类比 index_table_from_file和index_table_from_tensor的关系"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[b'emerson' b'lake' b'palmer' b'UNKK']\n",
      " [b'emerson' b'UNKK' b'UNKK' b'UNKK']]\n"
     ]
    }
   ],
   "source": [
    "mapping_string = tf.constant([\"emerson\", \"lake\", \"palmer\"])\n",
    "indices = tf.constant([[0, 1, 2, 3] ,[0 ,3 ,4, 9]], tf.int64)\n",
    "table_id_tensor = tf.contrib.lookup.index_to_string_table_from_tensor(\n",
    "    mapping_string, default_value=\"UNKK\")\n",
    "values = table_id_tensor.lookup(indices)\n",
    "\n",
    "with tf.Session() as sl:\n",
    "    sl.run(tf.tables_initializer())\n",
    "    print(sl.run(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "feature_column",
   "language": "python",
   "name": "fc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
